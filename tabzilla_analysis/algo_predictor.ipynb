{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display_html\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from metadata_utils import get_metadata, get_tuned_alg_perf, process_metafeatures, compute_feature_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_version = \"_v0\"\n",
    "# For choosing metafeatures\n",
    "filter_families = [\n",
    "    'general',\n",
    "    'statistical',\n",
    "    'info-theory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishak/Desktop/group/Tabular/metadataset2/metadata_utils.py:56: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  metafeatures_processed = metafeatures_df.fillna(metafeatures_df.median())\n"
     ]
    }
   ],
   "source": [
    "metadataset_df, metafeatures_df = get_metadata(dataset_version)\n",
    "\n",
    "metafeatures_processed = process_metafeatures(metafeatures_df, filter_families=filter_families)\n",
    "metafeatures_df = metafeatures_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"F1\" # Choices: \"Accuracy\", \"F1\", \"Log Loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>results_bucket_path</th>\n",
       "      <th>dataset_fold_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>alg_name</th>\n",
       "      <th>hparam_source</th>\n",
       "      <th>trial_number</th>\n",
       "      <th>alg_hparam_id</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>time__train</th>\n",
       "      <th>Log Loss__train</th>\n",
       "      <th>...</th>\n",
       "      <th>AUC__test</th>\n",
       "      <th>Accuracy__test</th>\n",
       "      <th>F1__test</th>\n",
       "      <th>time__train-eval</th>\n",
       "      <th>MSE__train</th>\n",
       "      <th>R2__train</th>\n",
       "      <th>MSE__val</th>\n",
       "      <th>R2__val</th>\n",
       "      <th>MSE__test</th>\n",
       "      <th>R2__test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>results/openml__APSFailure__168868/CatBoost/gp...</td>\n",
       "      <td>openml__APSFailure__168868__fold_0</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>random_27_s0</td>\n",
       "      <td>27</td>\n",
       "      <td>CatBoost__seed_0__trial_27</td>\n",
       "      <td>gpu-expt-a_091822_065111_fdd9.zip</td>\n",
       "      <td>5.285700</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990643</td>\n",
       "      <td>0.994211</td>\n",
       "      <td>0.994211</td>\n",
       "      <td>0.146698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>results/openml__APSFailure__168868/CatBoost/gp...</td>\n",
       "      <td>openml__APSFailure__168868__fold_1</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>random_3_s0</td>\n",
       "      <td>3</td>\n",
       "      <td>CatBoost__seed_0__trial_3</td>\n",
       "      <td>gpu-expt-a_091822_065111_fdd9.zip</td>\n",
       "      <td>3.450149</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988862</td>\n",
       "      <td>0.992105</td>\n",
       "      <td>0.992105</td>\n",
       "      <td>0.140466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>results/openml__APSFailure__168868/CatBoost/gp...</td>\n",
       "      <td>openml__APSFailure__168868__fold_2</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>random_8_s0</td>\n",
       "      <td>8</td>\n",
       "      <td>CatBoost__seed_0__trial_8</td>\n",
       "      <td>gpu-expt-a_091822_065111_fdd9.zip</td>\n",
       "      <td>11.938921</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995551</td>\n",
       "      <td>0.993421</td>\n",
       "      <td>0.993421</td>\n",
       "      <td>0.173912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>results/openml__APSFailure__168868/CatBoost/gp...</td>\n",
       "      <td>openml__APSFailure__168868__fold_3</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>random_20_s0</td>\n",
       "      <td>20</td>\n",
       "      <td>CatBoost__seed_0__trial_20</td>\n",
       "      <td>gpu-expt-a_091822_065111_fdd9.zip</td>\n",
       "      <td>7.538957</td>\n",
       "      <td>0.011646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991612</td>\n",
       "      <td>0.994868</td>\n",
       "      <td>0.994868</td>\n",
       "      <td>0.179523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>results/openml__APSFailure__168868/CatBoost/gp...</td>\n",
       "      <td>openml__APSFailure__168868__fold_4</td>\n",
       "      <td>openml__APSFailure__168868</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>random_8_s0</td>\n",
       "      <td>8</td>\n",
       "      <td>CatBoost__seed_0__trial_8</td>\n",
       "      <td>gpu-expt-a_091822_065111_fdd9.zip</td>\n",
       "      <td>11.805938</td>\n",
       "      <td>0.007725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989614</td>\n",
       "      <td>0.995658</td>\n",
       "      <td>0.995658</td>\n",
       "      <td>0.179625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191448</th>\n",
       "      <td>results/openml__wilt__146820/XGBoost/gpu-expt-...</td>\n",
       "      <td>openml__wilt__146820__fold_5</td>\n",
       "      <td>openml__wilt__146820</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>default</td>\n",
       "      <td>0</td>\n",
       "      <td>XGBoost__seed_0__trial_0</td>\n",
       "      <td>gpu-expt-a_091722_220903_21b9.zip</td>\n",
       "      <td>0.142135</td>\n",
       "      <td>0.039770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191671</th>\n",
       "      <td>results/openml__wilt__146820/XGBoost/gpu-expt-...</td>\n",
       "      <td>openml__wilt__146820__fold_6</td>\n",
       "      <td>openml__wilt__146820</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>random_22_s0</td>\n",
       "      <td>22</td>\n",
       "      <td>XGBoost__seed_0__trial_22</td>\n",
       "      <td>gpu-expt-a_091722_220903_21b9.zip</td>\n",
       "      <td>0.116242</td>\n",
       "      <td>0.022093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997229</td>\n",
       "      <td>0.985537</td>\n",
       "      <td>0.985537</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191865</th>\n",
       "      <td>results/openml__wilt__146820/XGBoost/gpu-expt-...</td>\n",
       "      <td>openml__wilt__146820__fold_7</td>\n",
       "      <td>openml__wilt__146820</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>random_1_s0</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoost__seed_0__trial_1</td>\n",
       "      <td>gpu-expt-a_091722_220903_21b9.zip</td>\n",
       "      <td>0.235586</td>\n",
       "      <td>0.032988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996977</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192092</th>\n",
       "      <td>results/openml__wilt__146820/XGBoost/gpu-expt-...</td>\n",
       "      <td>openml__wilt__146820__fold_8</td>\n",
       "      <td>openml__wilt__146820</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>random_27_s0</td>\n",
       "      <td>27</td>\n",
       "      <td>XGBoost__seed_0__trial_27</td>\n",
       "      <td>gpu-expt-a_091722_220903_21b9.zip</td>\n",
       "      <td>0.120812</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994732</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192304</th>\n",
       "      <td>results/openml__wilt__146820/XGBoost/gpu-expt-...</td>\n",
       "      <td>openml__wilt__146820__fold_9</td>\n",
       "      <td>openml__wilt__146820</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>random_4_s0</td>\n",
       "      <td>4</td>\n",
       "      <td>XGBoost__seed_0__trial_4</td>\n",
       "      <td>gpu-expt-a_091722_220903_21b9.zip</td>\n",
       "      <td>0.138495</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998569</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.991718</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6460 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      results_bucket_path  \\\n",
       "20      results/openml__APSFailure__168868/CatBoost/gp...   \n",
       "150     results/openml__APSFailure__168868/CatBoost/gp...   \n",
       "282     results/openml__APSFailure__168868/CatBoost/gp...   \n",
       "394     results/openml__APSFailure__168868/CatBoost/gp...   \n",
       "536     results/openml__APSFailure__168868/CatBoost/gp...   \n",
       "...                                                   ...   \n",
       "191448  results/openml__wilt__146820/XGBoost/gpu-expt-...   \n",
       "191671  results/openml__wilt__146820/XGBoost/gpu-expt-...   \n",
       "191865  results/openml__wilt__146820/XGBoost/gpu-expt-...   \n",
       "192092  results/openml__wilt__146820/XGBoost/gpu-expt-...   \n",
       "192304  results/openml__wilt__146820/XGBoost/gpu-expt-...   \n",
       "\n",
       "                           dataset_fold_id                dataset_name  \\\n",
       "20      openml__APSFailure__168868__fold_0  openml__APSFailure__168868   \n",
       "150     openml__APSFailure__168868__fold_1  openml__APSFailure__168868   \n",
       "282     openml__APSFailure__168868__fold_2  openml__APSFailure__168868   \n",
       "394     openml__APSFailure__168868__fold_3  openml__APSFailure__168868   \n",
       "536     openml__APSFailure__168868__fold_4  openml__APSFailure__168868   \n",
       "...                                    ...                         ...   \n",
       "191448        openml__wilt__146820__fold_5        openml__wilt__146820   \n",
       "191671        openml__wilt__146820__fold_6        openml__wilt__146820   \n",
       "191865        openml__wilt__146820__fold_7        openml__wilt__146820   \n",
       "192092        openml__wilt__146820__fold_8        openml__wilt__146820   \n",
       "192304        openml__wilt__146820__fold_9        openml__wilt__146820   \n",
       "\n",
       "        alg_name hparam_source  trial_number               alg_hparam_id  \\\n",
       "20      CatBoost  random_27_s0            27  CatBoost__seed_0__trial_27   \n",
       "150     CatBoost   random_3_s0             3   CatBoost__seed_0__trial_3   \n",
       "282     CatBoost   random_8_s0             8   CatBoost__seed_0__trial_8   \n",
       "394     CatBoost  random_20_s0            20  CatBoost__seed_0__trial_20   \n",
       "536     CatBoost   random_8_s0             8   CatBoost__seed_0__trial_8   \n",
       "...          ...           ...           ...                         ...   \n",
       "191448   XGBoost       default             0    XGBoost__seed_0__trial_0   \n",
       "191671   XGBoost  random_22_s0            22   XGBoost__seed_0__trial_22   \n",
       "191865   XGBoost   random_1_s0             1    XGBoost__seed_0__trial_1   \n",
       "192092   XGBoost  random_27_s0            27   XGBoost__seed_0__trial_27   \n",
       "192304   XGBoost   random_4_s0             4    XGBoost__seed_0__trial_4   \n",
       "\n",
       "                                 exp_name  time__train  Log Loss__train  ...  \\\n",
       "20      gpu-expt-a_091822_065111_fdd9.zip     5.285700         0.012935  ...   \n",
       "150     gpu-expt-a_091822_065111_fdd9.zip     3.450149         0.011320  ...   \n",
       "282     gpu-expt-a_091822_065111_fdd9.zip    11.938921         0.007183  ...   \n",
       "394     gpu-expt-a_091822_065111_fdd9.zip     7.538957         0.011646  ...   \n",
       "536     gpu-expt-a_091822_065111_fdd9.zip    11.805938         0.007725  ...   \n",
       "...                                   ...          ...              ...  ...   \n",
       "191448  gpu-expt-a_091722_220903_21b9.zip     0.142135         0.039770  ...   \n",
       "191671  gpu-expt-a_091722_220903_21b9.zip     0.116242         0.022093  ...   \n",
       "191865  gpu-expt-a_091722_220903_21b9.zip     0.235586         0.032988  ...   \n",
       "192092  gpu-expt-a_091722_220903_21b9.zip     0.120812         0.016541  ...   \n",
       "192304  gpu-expt-a_091722_220903_21b9.zip     0.138495         0.013784  ...   \n",
       "\n",
       "        AUC__test  Accuracy__test  F1__test  time__train-eval  MSE__train  \\\n",
       "20       0.990643        0.994211  0.994211          0.146698         NaN   \n",
       "150      0.988862        0.992105  0.992105          0.140466         NaN   \n",
       "282      0.995551        0.993421  0.993421          0.173912         NaN   \n",
       "394      0.991612        0.994868  0.994868          0.179523         NaN   \n",
       "536      0.989614        0.995658  0.995658          0.179625         NaN   \n",
       "...           ...             ...       ...               ...         ...   \n",
       "191448   0.955786        0.983471  0.983471          0.006239         NaN   \n",
       "191671   0.997229        0.985537  0.985537          0.003031         NaN   \n",
       "191865   0.996977        0.983471  0.983471          0.006548         NaN   \n",
       "192092   0.994732        0.991736  0.991736          0.005032         NaN   \n",
       "192304   0.998569        0.991718  0.991718          0.005978         NaN   \n",
       "\n",
       "        R2__train  MSE__val  R2__val  MSE__test  R2__test  \n",
       "20            NaN       NaN      NaN        NaN       NaN  \n",
       "150           NaN       NaN      NaN        NaN       NaN  \n",
       "282           NaN       NaN      NaN        NaN       NaN  \n",
       "394           NaN       NaN      NaN        NaN       NaN  \n",
       "536           NaN       NaN      NaN        NaN       NaN  \n",
       "...           ...       ...      ...        ...       ...  \n",
       "191448        NaN       NaN      NaN        NaN       NaN  \n",
       "191671        NaN       NaN      NaN        NaN       NaN  \n",
       "191865        NaN       NaN      NaN        NaN       NaN  \n",
       "192092        NaN       NaN      NaN        NaN       NaN  \n",
       "192304        NaN       NaN      NaN        NaN       NaN  \n",
       "\n",
       "[6460 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_alg_perf = get_tuned_alg_perf(metadataset_df, metric=metric)\n",
    "tuned_alg_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = tuned_alg_perf.merge(metafeatures_df, right_on=\"dataset_name\", left_on=\"dataset_fold_id\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_columns = [col_name for col_name in joined_df if col_name.startswith(\"f__\")]\n",
    "f1_test = ['F1__test', 'alg_name']\n",
    "features = corr_columns + f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-1d9c04ed1ef1>:1: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  data = joined_df[joined_df.columns & features]\n"
     ]
    }
   ],
   "source": [
    "data = joined_df[joined_df.columns & features]\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg_name</th>\n",
       "      <th>F1__test</th>\n",
       "      <th>f__pymfe.general.attr_to_inst</th>\n",
       "      <th>f__pymfe.general.cat_to_num</th>\n",
       "      <th>f__pymfe.general.freq_class.count</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.0</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.1</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.2</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.3</th>\n",
       "      <th>f__pymfe.general.freq_class.histogram.4</th>\n",
       "      <th>...</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.quantiles.1</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.quantiles.2</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.quantiles.3</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.quantiles.4</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.range</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.sd</th>\n",
       "      <th>f__pymfe.info-theory.mut_inf.skewness</th>\n",
       "      <th>f__pymfe.info-theory.ns_ratio</th>\n",
       "      <th>f__pymfe.statistical.iq_range</th>\n",
       "      <th>f__pymfe.statistical.t_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.917247</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>1.022602</td>\n",
       "      <td>38.780852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearModel</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.048636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>1.022602</td>\n",
       "      <td>38.780852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.992881</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>1.022602</td>\n",
       "      <td>38.780852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.997801</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>1.022602</td>\n",
       "      <td>38.780852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.887381</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>1.022602</td>\n",
       "      <td>38.780852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6455</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.663317</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015825</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>0.030687</td>\n",
       "      <td>0.051745</td>\n",
       "      <td>0.050152</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.241687</td>\n",
       "      <td>199.413060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6456</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.195738</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>1.022602</td>\n",
       "      <td>38.780852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6457</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.750219</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>1.022602</td>\n",
       "      <td>38.780852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.981470</td>\n",
       "      <td>0.089120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>1.022602</td>\n",
       "      <td>38.780852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.936759</td>\n",
       "      <td>0.035503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008414</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.036939</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>0.129517</td>\n",
       "      <td>0.036463</td>\n",
       "      <td>1.022602</td>\n",
       "      <td>38.780852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6460 rows × 652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         alg_name  F1__test  f__pymfe.general.attr_to_inst  \\\n",
       "0         XGBoost  0.917247                       0.990741   \n",
       "1     LinearModel  0.849057                       0.048636   \n",
       "2             SVM  0.992881                       0.014235   \n",
       "3             KNN  0.997801                       0.000194   \n",
       "4             KNN  0.887381                       0.990741   \n",
       "...           ...       ...                            ...   \n",
       "6455     CatBoost  0.663317                       0.000016   \n",
       "6456          KNN  0.195738                       0.000518   \n",
       "6457          KNN  0.750219                       0.000878   \n",
       "6458     CatBoost  0.981470                       0.089120   \n",
       "6459       TabNet  0.936759                       0.035503   \n",
       "\n",
       "      f__pymfe.general.cat_to_num  f__pymfe.general.freq_class.count  \\\n",
       "0                        0.000000                                  9   \n",
       "1                        0.000000                                  2   \n",
       "2                        0.000000                                 10   \n",
       "3                        0.000000                                  7   \n",
       "4                        0.000000                                  9   \n",
       "...                           ...                                ...   \n",
       "6455                     1.333333                                  2   \n",
       "6456                     0.000000                                100   \n",
       "6457                     0.000000                                  2   \n",
       "6458                     0.000000                                  8   \n",
       "6459                     0.000000                                  2   \n",
       "\n",
       "      f__pymfe.general.freq_class.histogram.0  \\\n",
       "0                                    0.000000   \n",
       "1                                    0.500000   \n",
       "2                                    0.300000   \n",
       "3                                    0.714286   \n",
       "4                                    0.000000   \n",
       "...                                       ...   \n",
       "6455                                 0.500000   \n",
       "6456                                 0.640000   \n",
       "6457                                 0.500000   \n",
       "6458                                 0.125000   \n",
       "6459                                 0.500000   \n",
       "\n",
       "      f__pymfe.general.freq_class.histogram.1  \\\n",
       "0                                    0.000000   \n",
       "1                                    0.000000   \n",
       "2                                    0.100000   \n",
       "3                                    0.142857   \n",
       "4                                    0.000000   \n",
       "...                                       ...   \n",
       "6455                                 0.000000   \n",
       "6456                                 0.170000   \n",
       "6457                                 0.000000   \n",
       "6458                                 0.000000   \n",
       "6459                                 0.000000   \n",
       "\n",
       "      f__pymfe.general.freq_class.histogram.2  \\\n",
       "0                                        0.00   \n",
       "1                                        0.00   \n",
       "2                                        0.10   \n",
       "3                                        0.00   \n",
       "4                                        0.00   \n",
       "...                                       ...   \n",
       "6455                                     0.00   \n",
       "6456                                     0.05   \n",
       "6457                                     0.00   \n",
       "6458                                     0.00   \n",
       "6459                                     0.00   \n",
       "\n",
       "      f__pymfe.general.freq_class.histogram.3  \\\n",
       "0                                        0.00   \n",
       "1                                        0.00   \n",
       "2                                        0.10   \n",
       "3                                        0.00   \n",
       "4                                        0.00   \n",
       "...                                       ...   \n",
       "6455                                     0.00   \n",
       "6456                                     0.01   \n",
       "6457                                     0.00   \n",
       "6458                                     0.00   \n",
       "6459                                     0.00   \n",
       "\n",
       "      f__pymfe.general.freq_class.histogram.4  ...  \\\n",
       "0                                        0.00  ...   \n",
       "1                                        0.00  ...   \n",
       "2                                        0.00  ...   \n",
       "3                                        0.00  ...   \n",
       "4                                        0.00  ...   \n",
       "...                                       ...  ...   \n",
       "6455                                     0.00  ...   \n",
       "6456                                     0.06  ...   \n",
       "6457                                     0.00  ...   \n",
       "6458                                     0.00  ...   \n",
       "6459                                     0.00  ...   \n",
       "\n",
       "      f__pymfe.info-theory.mut_inf.quantiles.1  \\\n",
       "0                                     0.008414   \n",
       "1                                     0.008414   \n",
       "2                                     0.008414   \n",
       "3                                     0.008414   \n",
       "4                                     0.008414   \n",
       "...                                        ...   \n",
       "6455                                  0.015825   \n",
       "6456                                  0.008414   \n",
       "6457                                  0.008414   \n",
       "6458                                  0.008414   \n",
       "6459                                  0.008414   \n",
       "\n",
       "      f__pymfe.info-theory.mut_inf.quantiles.2  \\\n",
       "0                                     0.018632   \n",
       "1                                     0.018632   \n",
       "2                                     0.018632   \n",
       "3                                     0.018632   \n",
       "4                                     0.018632   \n",
       "...                                        ...   \n",
       "6455                                  0.022118   \n",
       "6456                                  0.018632   \n",
       "6457                                  0.018632   \n",
       "6458                                  0.018632   \n",
       "6459                                  0.018632   \n",
       "\n",
       "      f__pymfe.info-theory.mut_inf.quantiles.3  \\\n",
       "0                                     0.036939   \n",
       "1                                     0.036939   \n",
       "2                                     0.036939   \n",
       "3                                     0.036939   \n",
       "4                                     0.036939   \n",
       "...                                        ...   \n",
       "6455                                  0.030687   \n",
       "6456                                  0.036939   \n",
       "6457                                  0.036939   \n",
       "6458                                  0.036939   \n",
       "6459                                  0.036939   \n",
       "\n",
       "      f__pymfe.info-theory.mut_inf.quantiles.4  \\\n",
       "0                                     0.132105   \n",
       "1                                     0.132105   \n",
       "2                                     0.132105   \n",
       "3                                     0.132105   \n",
       "4                                     0.132105   \n",
       "...                                        ...   \n",
       "6455                                  0.051745   \n",
       "6456                                  0.132105   \n",
       "6457                                  0.132105   \n",
       "6458                                  0.132105   \n",
       "6459                                  0.132105   \n",
       "\n",
       "      f__pymfe.info-theory.mut_inf.range  f__pymfe.info-theory.mut_inf.sd  \\\n",
       "0                               0.129517                         0.036463   \n",
       "1                               0.129517                         0.036463   \n",
       "2                               0.129517                         0.036463   \n",
       "3                               0.129517                         0.036463   \n",
       "4                               0.129517                         0.036463   \n",
       "...                                  ...                              ...   \n",
       "6455                            0.050152                         0.020681   \n",
       "6456                            0.129517                         0.036463   \n",
       "6457                            0.129517                         0.036463   \n",
       "6458                            0.129517                         0.036463   \n",
       "6459                            0.129517                         0.036463   \n",
       "\n",
       "      f__pymfe.info-theory.mut_inf.skewness  f__pymfe.info-theory.ns_ratio  \\\n",
       "0                                  1.022602                      38.780852   \n",
       "1                                  1.022602                      38.780852   \n",
       "2                                  1.022602                      38.780852   \n",
       "3                                  1.022602                      38.780852   \n",
       "4                                  1.022602                      38.780852   \n",
       "...                                     ...                            ...   \n",
       "6455                               0.241687                     199.413060   \n",
       "6456                               1.022602                      38.780852   \n",
       "6457                               1.022602                      38.780852   \n",
       "6458                               1.022602                      38.780852   \n",
       "6459                               1.022602                      38.780852   \n",
       "\n",
       "      f__pymfe.statistical.iq_range  f__pymfe.statistical.t_mean  \n",
       "0                               NaN                          NaN  \n",
       "1                               NaN                          NaN  \n",
       "2                               NaN                          NaN  \n",
       "3                               NaN                          NaN  \n",
       "4                               NaN                          NaN  \n",
       "...                             ...                          ...  \n",
       "6455                            NaN                          NaN  \n",
       "6456                            NaN                          NaN  \n",
       "6457                            NaN                          NaN  \n",
       "6458                            NaN                          NaN  \n",
       "6459                            NaN                          NaN  \n",
       "\n",
       "[6460 rows x 652 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_test(data):\n",
    "\n",
    "    x = data[data.columns & corr_columns]\n",
    "    x = x.fillna(0)\n",
    "    print(x.isnull().values.any())\n",
    "    #X = x.values.reshape(-1, 650)\n",
    "\n",
    "    y = data['F1__test']\n",
    "    Y = y.values.reshape(-1, 1)\n",
    "    \n",
    "    \n",
    "    return x, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(data):\n",
    "    c = data['alg_name']\n",
    "    c = pd.get_dummies(c)\n",
    "    C = c.values.reshape(-1, 7)\n",
    "\n",
    "    x = data[data.columns & corr_columns]\n",
    "    x = x.fillna(0)\n",
    "    print(x.isnull().values.any())\n",
    "    X = x.values.reshape(-1, 650)\n",
    "\n",
    "    y = data['F1__test']\n",
    "    Y = y.values.reshape(-1, 1)\n",
    "    X1 = np.concatenate((X, C), axis=1)\n",
    "    \n",
    "    return X1, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "algos = metadataset_df['alg_name'].unique()\n",
    "algos = pd.get_dummies(algos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LinearModel</th>\n",
       "      <th>MLP</th>\n",
       "      <th>SVM</th>\n",
       "      <th>TabNet</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CatBoost  KNN  LinearModel  MLP  SVM  TabNet  XGBoost\n",
       "0         1    0            0    0    0       0        0\n",
       "1         0    1            0    0    0       0        0\n",
       "2         0    0            1    0    0       0        0\n",
       "3         0    0            0    1    0       0        0\n",
       "4         0    0            0    0    0       0        1\n",
       "5         0    0            0    0    1       0        0\n",
       "6         0    0            0    0    0       1        0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_index = ['CatBoost', 'KNN', 'LinearModel', 'MLP', 'SVM', 'TabNet', 'XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_per_row(A, B):\n",
    "    m1,n1 = A.shape\n",
    "    m2,n2 = B.shape\n",
    "\n",
    "    out = np.zeros((m1,m2,n1+n2),dtype=A.dtype)\n",
    "    out[:,:,:n1] = A[:,None,:]\n",
    "    out[:,:,n1:] = B\n",
    "    return out.reshape(m1*m2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(lst):\n",
    "    ind = []\n",
    "    window_size = 7\n",
    "    for i in range(int(len(lst)/window_size)):\n",
    "        l = lst[i*window_size:(i+1)*window_size]\n",
    "        ind.append(l.index(max(l)))\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(X_test):\n",
    "    algos = metadataset_df['alg_name'].unique()\n",
    "    algos = pd.get_dummies(algos)\n",
    "    X = X_test.values.reshape(-1, 650)\n",
    "    x1 = concatenate_per_row(X, algos)\n",
    "    Y_pred = linear_regressor.predict(x1)\n",
    "    Y_pred = Y_pred.tolist()\n",
    "    indices = get_indices(Y_pred)\n",
    "    preds=[]\n",
    "    for i in indices:\n",
    "        preds.append(algo_index[i])\n",
    "        \n",
    "    return preds, Y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0.24020208857583147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-4db4a8a1292c>:6: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  x = data[data.columns & corr_columns]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = get_xy(train)\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_train, Y_train)\n",
    "r_squared = linear_regressor.score(X_train, Y_train)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_algo(dataset, metric):\n",
    "    temp_df = metadataset_df.loc[metadataset_df['dataset_name'] == dataset]\n",
    "    return temp_df.loc[temp_df[metric].idxmax()]['alg_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(a):\n",
    "    dataset=\"\"\n",
    "    a = a.fillna(0)\n",
    "    a=a.values.tolist()\n",
    "    a=[ '%.6f' % elem for elem in a ]\n",
    "    a=[float(i) for i in a]\n",
    "    for index, row in metafeatures_df.iterrows():\n",
    "        row = row.fillna(0)\n",
    "        row = row.values.tolist()\n",
    "        dataset_current = row[0]\n",
    "        row = row[1:]\n",
    "        #print(row)\n",
    "        row=[ '%.6f' % elem for elem in row ]\n",
    "        row=[float(i) for i in row]\n",
    "\n",
    "\n",
    "        if (row == a):\n",
    "            dataset = dataset_current\n",
    "    #print(dataset)\n",
    "    #print(dataset[0:-8])\n",
    "    return dataset[0:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truths(X_test):\n",
    "    ground_truths=[]\n",
    "    metric='F1__test'\n",
    "    for index, row in X_test.iterrows():\n",
    "        print(index)\n",
    "        dataset_name = get_dataset_name(row)\n",
    "        if (dataset_name == \"\"):\n",
    "            print(\"Error: No dataset returned\")\n",
    "        best_algo = get_best_algo(dataset_name, metric)\n",
    "        ground_truths.append(best_algo)\n",
    "    return ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-bb1c473b762a>:3: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  x = data[data.columns & corr_columns]\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = get_xy_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975\n",
      "3837\n",
      "3847\n",
      "100\n",
      "4399\n",
      "2760\n",
      "6405\n",
      "3420\n",
      "6165\n",
      "3125\n",
      "2652\n",
      "927\n",
      "2867\n",
      "1944\n",
      "2920\n",
      "5663\n",
      "2241\n",
      "377\n",
      "1170\n",
      "5386\n",
      "773\n",
      "3559\n",
      "4021\n",
      "2437\n",
      "6261\n",
      "3247\n",
      "3398\n",
      "3901\n",
      "595\n",
      "1133\n",
      "2103\n",
      "2128\n",
      "1379\n",
      "549\n",
      "4927\n",
      "26\n",
      "4604\n",
      "3594\n",
      "1822\n",
      "6432\n",
      "1050\n",
      "1694\n",
      "2282\n",
      "3261\n",
      "3550\n",
      "4947\n",
      "2002\n",
      "5813\n",
      "4366\n",
      "3299\n",
      "1157\n",
      "4644\n",
      "2403\n",
      "2480\n",
      "5485\n",
      "2157\n",
      "340\n",
      "425\n",
      "736\n",
      "4667\n",
      "3202\n",
      "3495\n",
      "1963\n",
      "5293\n",
      "4807\n",
      "3143\n",
      "4727\n",
      "5079\n",
      "3884\n",
      "785\n",
      "1187\n",
      "2875\n",
      "1506\n",
      "1079\n",
      "3544\n",
      "4619\n",
      "3648\n",
      "468\n",
      "6259\n",
      "3596\n",
      "4881\n",
      "5699\n",
      "1957\n",
      "1239\n",
      "3733\n",
      "688\n",
      "4841\n",
      "6122\n",
      "1034\n",
      "6024\n",
      "76\n",
      "552\n",
      "5873\n",
      "2009\n",
      "115\n",
      "1542\n",
      "2427\n",
      "1140\n",
      "236\n",
      "5103\n",
      "2704\n",
      "3448\n",
      "6268\n",
      "3571\n",
      "1059\n",
      "2971\n",
      "1286\n",
      "3849\n",
      "3026\n",
      "3695\n",
      "4403\n",
      "1161\n",
      "1091\n",
      "2702\n",
      "85\n",
      "3256\n",
      "2772\n",
      "3846\n",
      "792\n",
      "1367\n",
      "6092\n",
      "3397\n",
      "4315\n",
      "1520\n",
      "4480\n",
      "5245\n",
      "5170\n",
      "1579\n",
      "4763\n",
      "5908\n",
      "1437\n",
      "5770\n",
      "847\n",
      "4018\n",
      "864\n",
      "1643\n",
      "5856\n",
      "678\n",
      "1241\n",
      "4867\n",
      "2866\n",
      "4215\n",
      "5676\n",
      "4163\n",
      "3497\n",
      "6447\n",
      "2297\n",
      "684\n",
      "427\n",
      "2636\n",
      "3894\n",
      "6161\n",
      "5279\n",
      "2124\n",
      "5294\n",
      "5204\n",
      "911\n",
      "1418\n",
      "1472\n",
      "1297\n",
      "6253\n",
      "5410\n",
      "2337\n",
      "1561\n",
      "272\n",
      "2869\n",
      "1874\n",
      "2529\n",
      "498\n",
      "1306\n",
      "568\n",
      "6197\n",
      "1624\n",
      "158\n",
      "3238\n",
      "6439\n",
      "5693\n",
      "3115\n",
      "998\n",
      "637\n",
      "2808\n",
      "952\n",
      "1901\n",
      "364\n",
      "5109\n",
      "1483\n",
      "5263\n",
      "2828\n",
      "4286\n",
      "2126\n",
      "4138\n",
      "4057\n",
      "4451\n",
      "3563\n",
      "5518\n",
      "6059\n",
      "4677\n",
      "6143\n",
      "4489\n",
      "6108\n",
      "19\n",
      "580\n",
      "5968\n",
      "3981\n",
      "1242\n",
      "4960\n",
      "3391\n",
      "4469\n",
      "3714\n",
      "676\n",
      "4390\n",
      "1914\n",
      "3457\n",
      "2089\n",
      "251\n",
      "408\n",
      "1551\n",
      "2021\n",
      "2780\n",
      "2922\n",
      "1935\n",
      "612\n",
      "4450\n",
      "3660\n",
      "719\n",
      "4258\n",
      "3151\n",
      "4414\n",
      "6086\n",
      "5730\n",
      "1261\n",
      "5038\n",
      "3244\n",
      "5917\n",
      "4107\n",
      "2816\n",
      "782\n",
      "3182\n",
      "4899\n",
      "6221\n",
      "2353\n",
      "739\n",
      "5312\n",
      "1969\n",
      "6368\n",
      "1866\n",
      "1466\n",
      "179\n",
      "2491\n",
      "2207\n",
      "4835\n",
      "6157\n",
      "1705\n",
      "2041\n",
      "5747\n",
      "1820\n",
      "3123\n",
      "3139\n",
      "1821\n",
      "6264\n",
      "5133\n",
      "3094\n",
      "4935\n",
      "5319\n",
      "832\n",
      "1677\n",
      "2595\n",
      "740\n",
      "5606\n",
      "217\n",
      "742\n",
      "5599\n",
      "2995\n",
      "3159\n",
      "2512\n",
      "3790\n",
      "2979\n",
      "967\n",
      "3049\n",
      "5901\n",
      "5971\n",
      "3528\n",
      "4148\n",
      "333\n",
      "5491\n",
      "3446\n",
      "2672\n",
      "358\n",
      "500\n",
      "5850\n",
      "6051\n",
      "1983\n",
      "991\n",
      "6168\n",
      "4853\n",
      "1847\n",
      "1652\n",
      "1664\n",
      "3524\n",
      "2336\n",
      "36\n",
      "3362\n",
      "2073\n",
      "1665\n",
      "3284\n",
      "5633\n",
      "2304\n",
      "2767\n",
      "2186\n",
      "1442\n",
      "4893\n",
      "585\n",
      "365\n",
      "1328\n",
      "6003\n",
      "915\n",
      "2290\n",
      "5154\n",
      "1490\n",
      "1531\n",
      "1662\n",
      "4149\n",
      "4485\n",
      "5718\n",
      "1330\n",
      "5364\n",
      "2905\n",
      "5640\n",
      "2769\n",
      "5471\n",
      "519\n",
      "3641\n",
      "4607\n",
      "2632\n",
      "842\n",
      "6040\n",
      "1700\n",
      "3399\n",
      "1764\n",
      "5694\n",
      "4492\n",
      "4941\n",
      "5527\n",
      "2387\n",
      "933\n",
      "1155\n",
      "4076\n",
      "2339\n",
      "1835\n",
      "5489\n",
      "1459\n",
      "1269\n",
      "5808\n",
      "2309\n",
      "160\n",
      "5846\n",
      "1927\n",
      "3850\n",
      "2749\n",
      "6214\n",
      "5866\n",
      "3050\n",
      "2729\n",
      "789\n",
      "1518\n",
      "2721\n",
      "5660\n",
      "5551\n",
      "3779\n",
      "1766\n",
      "1460\n",
      "1424\n",
      "5178\n",
      "4736\n",
      "3102\n",
      "420\n",
      "6311\n",
      "4033\n",
      "1422\n",
      "4525\n",
      "4994\n",
      "477\n",
      "2117\n",
      "3968\n",
      "2031\n",
      "731\n",
      "6050\n",
      "1893\n",
      "4631\n",
      "4785\n",
      "2484\n",
      "2619\n",
      "4708\n",
      "1897\n",
      "3093\n",
      "5775\n",
      "5716\n",
      "1359\n",
      "3636\n",
      "6\n",
      "231\n",
      "1145\n",
      "1556\n",
      "4458\n",
      "347\n",
      "4905\n",
      "5025\n",
      "3327\n",
      "3485\n",
      "5203\n",
      "5618\n",
      "3326\n",
      "2877\n",
      "2038\n",
      "2272\n",
      "4682\n",
      "3663\n",
      "1759\n",
      "3798\n",
      "6134\n",
      "5845\n",
      "2014\n",
      "5248\n",
      "2683\n",
      "946\n",
      "3374\n",
      "2260\n",
      "5796\n",
      "4466\n",
      "2303\n",
      "5327\n",
      "1464\n",
      "3615\n",
      "5682\n",
      "5862\n",
      "6100\n",
      "620\n",
      "2679\n",
      "3784\n",
      "4325\n",
      "480\n",
      "4798\n",
      "5688\n",
      "4369\n",
      "4976\n",
      "3036\n",
      "2151\n",
      "4890\n",
      "5452\n",
      "1521\n",
      "5627\n",
      "3629\n",
      "2884\n",
      "4591\n",
      "3724\n",
      "1149\n",
      "4455\n",
      "4404\n",
      "4658\n",
      "3786\n",
      "1219\n",
      "3799\n",
      "4048\n",
      "898\n",
      "18\n",
      "2686\n",
      "3878\n",
      "5785\n",
      "5949\n",
      "1770\n",
      "2390\n",
      "1329\n",
      "130\n",
      "4411\n",
      "449\n",
      "3630\n",
      "1647\n",
      "5907\n",
      "1816\n",
      "4949\n",
      "1607\n",
      "296\n",
      "3318\n",
      "4573\n",
      "5863\n",
      "2467\n",
      "3809\n",
      "6380\n",
      "702\n",
      "2374\n",
      "4974\n",
      "3246\n",
      "1732\n",
      "3030\n",
      "2925\n",
      "711\n",
      "737\n",
      "5341\n",
      "4776\n",
      "4775\n",
      "705\n",
      "6075\n",
      "5853\n",
      "4306\n",
      "4316\n",
      "5462\n",
      "307\n",
      "6082\n",
      "4950\n",
      "2131\n",
      "4052\n",
      "1529\n",
      "1063\n",
      "546\n",
      "6387\n",
      "38\n",
      "285\n",
      "1152\n",
      "2514\n",
      "4934\n",
      "3181\n",
      "1908\n",
      "3547\n",
      "1960\n",
      "1945\n",
      "5420\n",
      "141\n",
      "5483\n",
      "948\n",
      "6335\n",
      "3727\n",
      "3691\n",
      "779\n",
      "3445\n",
      "2171\n",
      "878\n",
      "4520\n",
      "3752\n",
      "5091\n",
      "327\n",
      "389\n",
      "5021\n",
      "4729\n",
      "3373\n",
      "10\n",
      "4918\n",
      "4252\n",
      "3289\n",
      "2324\n",
      "2685\n",
      "1926\n",
      "3412\n",
      "2396\n",
      "4194\n",
      "4386\n",
      "6429\n",
      "2422\n",
      "1112\n",
      "1331\n",
      "1850\n",
      "5811\n",
      "972\n",
      "820\n",
      "6169\n",
      "5234\n",
      "569\n",
      "3332\n",
      "999\n",
      "2059\n",
      "5609\n",
      "276\n",
      "3245\n",
      "3196\n",
      "1263\n",
      "24\n",
      "3572\n",
      "997\n",
      "4303\n",
      "6252\n",
      "4073\n",
      "2057\n",
      "3150\n",
      "4690\n",
      "4799\n",
      "1931\n",
      "2327\n",
      "105\n",
      "3006\n",
      "4696\n",
      "5959\n",
      "4954\n",
      "2798\n",
      "4581\n",
      "2400\n",
      "1566\n",
      "496\n",
      "2315\n",
      "647\n",
      "5262\n",
      "767\n",
      "3090\n",
      "5930\n",
      "2457\n",
      "1875\n",
      "4821\n",
      "2181\n",
      "2074\n",
      "369\n",
      "320\n",
      "6412\n",
      "3022\n",
      "3939\n",
      "4686\n",
      "3368\n",
      "2361\n",
      "219\n",
      "1517\n",
      "1663\n",
      "2269\n",
      "4719\n",
      "1532\n",
      "1863\n",
      "2046\n",
      "5053\n",
      "2004\n",
      "2071\n",
      "2096\n",
      "6163\n",
      "4014\n",
      "1276\n",
      "6190\n",
      "4620\n",
      "1475\n",
      "5889\n",
      "732\n",
      "4606\n",
      "1803\n",
      "4999\n",
      "3308\n",
      "5695\n",
      "2295\n",
      "4618\n",
      "1861\n",
      "4640\n",
      "6057\n",
      "6348\n",
      "4536\n",
      "324\n",
      "1208\n",
      "1143\n",
      "3726\n",
      "1043\n",
      "1997\n",
      "3334\n",
      "640\n",
      "1993\n",
      "3748\n",
      "3424\n",
      "1471\n",
      "2800\n",
      "780\n",
      "714\n",
      "319\n",
      "2273\n",
      "3567\n",
      "4175\n",
      "4464\n",
      "3350\n",
      "279\n",
      "3956\n",
      "4653\n",
      "5411\n",
      "4879\n",
      "937\n",
      "22\n",
      "863\n",
      "5550\n",
      "1695\n",
      "4731\n",
      "5956\n",
      "4134\n",
      "1002\n",
      "3106\n",
      "5772\n",
      "4405\n",
      "1674\n",
      "4260\n",
      "5979\n",
      "4512\n",
      "963\n",
      "4600\n",
      "6156\n",
      "5000\n",
      "2806\n",
      "3962\n",
      "2659\n",
      "1692\n",
      "120\n",
      "409\n",
      "5767\n",
      "4139\n",
      "5525\n",
      "1209\n",
      "2342\n",
      "3065\n",
      "4705\n",
      "3709\n",
      "4300\n",
      "907\n",
      "1559\n",
      "4319\n",
      "2700\n",
      "1370\n",
      "5261\n",
      "685\n",
      "1751\n",
      "5497\n",
      "47\n",
      "5997\n",
      "4219\n",
      "3092\n",
      "2885\n",
      "242\n",
      "3820\n",
      "5899\n",
      "1444\n",
      "1396\n",
      "2060\n",
      "3873\n",
      "1027\n",
      "5095\n",
      "2654\n",
      "1061\n",
      "883\n",
      "6300\n",
      "5229\n",
      "4419\n",
      "5267\n",
      "3236\n",
      "4228\n",
      "2745\n",
      "6209\n",
      "1651\n",
      "1006\n",
      "769\n",
      "4332\n",
      "151\n",
      "6419\n",
      "4688\n",
      "3120\n",
      "4091\n",
      "433\n",
      "2474\n",
      "169\n",
      "2609\n",
      "3384\n",
      "6064\n",
      "643\n",
      "2947\n",
      "4764\n",
      "125\n",
      "3693\n",
      "6231\n",
      "2267\n",
      "3185\n",
      "4614\n",
      "2735\n",
      "4026\n",
      "4064\n",
      "3852\n",
      "4737\n",
      "4901\n",
      "835\n",
      "5519\n",
      "3251\n",
      "5446\n",
      "1005\n",
      "2879\n",
      "4096\n",
      "3593\n",
      "5905\n",
      "3262\n",
      "5871\n",
      "805\n",
      "3694\n",
      "802\n",
      "5536\n",
      "1068\n",
      "578\n",
      "4898\n",
      "988\n",
      "825\n",
      "976\n",
      "674\n",
      "1107\n",
      "501\n",
      "4135\n",
      "5829\n",
      "2218\n",
      "4887\n",
      "1884\n",
      "1463\n",
      "5096\n",
      "4582\n",
      "1968\n",
      "2977\n",
      "476\n",
      "3162\n",
      "751\n",
      "3979\n",
      "5020\n",
      "336\n",
      "2668\n",
      "6279\n",
      "2709\n",
      "3578\n",
      "6072\n",
      "653\n",
      "6027\n",
      "3710\n",
      "2058\n",
      "5758\n",
      "4202\n",
      "6022\n",
      "1849\n",
      "1013\n",
      "3105\n",
      "2035\n",
      "1111\n",
      "4683\n",
      "2199\n",
      "1752\n",
      "1658\n",
      "3581\n",
      "5728\n",
      "3518\n",
      "493\n",
      "4743\n",
      "1054\n",
      "4615\n",
      "2132\n",
      "5219\n",
      "935\n",
      "3217\n",
      "1086\n",
      "4075\n",
      "5624\n",
      "621\n",
      "4070\n",
      "2330\n",
      "2183\n",
      "2368\n",
      "1035\n",
      "1539\n",
      "6331\n",
      "2834\n",
      "1146\n",
      "1898\n",
      "4659\n",
      "3071\n",
      "3585\n",
      "2779\n",
      "1657\n",
      "1996\n",
      "5347\n",
      "2388\n",
      "3449\n",
      "5970\n",
      "2684\n",
      "1195\n",
      "2535\n",
      "3633\n",
      "5843\n",
      "3411\n",
      "4878\n",
      "5893\n",
      "589\n",
      "2850\n",
      "4720\n",
      "3719\n",
      "6350\n",
      "4268\n",
      "5886\n",
      "2444\n",
      "5732\n",
      "6404\n",
      "6033\n",
      "3510\n",
      "49\n",
      "1767\n",
      "2482\n",
      "4239\n",
      "5852\n",
      "762\n",
      "4152\n",
      "5284\n",
      "4207\n",
      "3576\n",
      "6105\n",
      "687\n",
      "1632\n",
      "4814\n",
      "1076\n",
      "4603\n",
      "5861\n",
      "3475\n",
      "2874\n",
      "3541\n",
      "5128\n",
      "2359\n",
      "3007\n",
      "5915\n",
      "411\n",
      "4145\n",
      "1060\n",
      "6031\n",
      "2284\n",
      "3583\n",
      "4838\n",
      "2030\n",
      "828\n",
      "4448\n",
      "4231\n",
      "4349\n",
      "4560\n",
      "323\n",
      "3824\n",
      "6029\n",
      "756\n",
      "1742\n",
      "6230\n",
      "4996\n",
      "2239\n",
      "2627\n",
      "4563\n",
      "1784\n",
      "2928\n",
      "1040\n",
      "2143\n",
      "3072\n",
      "3531\n",
      "3267\n",
      "163\n",
      "5875\n",
      "7\n",
      "192\n",
      "6376\n",
      "37\n",
      "3193\n",
      "4638\n",
      "905\n",
      "4859\n",
      "3930\n",
      "1116\n",
      "4503\n",
      "2385\n",
      "1235\n",
      "1646\n",
      "6278\n",
      "1758\n",
      "2432\n",
      "1183\n",
      "4584\n",
      "3776\n",
      "5966\n",
      "78\n",
      "4120\n",
      "3814\n",
      "5241\n",
      "6270\n",
      "3190\n",
      "5374\n",
      "545\n",
      "1801\n",
      "3890\n",
      "6351\n",
      "5859\n",
      "3227\n",
      "5556\n",
      "4045\n",
      "1307\n",
      "6189\n",
      "3989\n",
      "1230\n",
      "5560\n",
      "3130\n",
      "2357\n",
      "505\n",
      "5310\n",
      "4284\n",
      "1540\n",
      "4254\n",
      "5106\n",
      "2086\n",
      "1365\n",
      "3188\n",
      "2998\n",
      "4104\n",
      "6035\n",
      "2264\n",
      "6182\n",
      "4773\n",
      "3055\n",
      "450\n",
      "515\n",
      "1857\n",
      "2018\n",
      "4346\n",
      "2335\n",
      "1497\n",
      "2842\n",
      "1544\n",
      "2835\n",
      "2259\n",
      "5325\n",
      "6307\n",
      "3467\n",
      "5356\n",
      "2562\n",
      "5465\n",
      "957\n",
      "5944\n",
      "4797\n",
      "4118\n",
      "6026\n",
      "2516\n",
      "1404\n",
      "3241\n",
      "5709\n",
      "4089\n",
      "1858\n",
      "4522\n",
      "1789\n",
      "1381\n",
      "4836\n",
      "3043\n",
      "2098\n",
      "6239\n",
      "4839\n",
      "5058\n",
      "1645\n",
      "758\n",
      "3018\n",
      "3098\n",
      "6119\n",
      "2948\n",
      "3564\n",
      "5771\n",
      "850\n",
      "4537\n",
      "2504\n",
      "3907\n",
      "3356\n",
      "6345\n",
      "5740\n",
      "1000\n",
      "3214\n",
      "4360\n",
      "6457\n",
      "6220\n",
      "617\n",
      "5209\n",
      "579\n",
      "6282\n",
      "1701\n",
      "2941\n",
      "1678\n",
      "5552\n",
      "3987\n",
      "2677\n",
      "3044\n",
      "6039\n",
      "3325\n",
      "5130\n",
      "5586\n",
      "3984\n",
      "2420\n",
      "4122\n",
      "2566\n",
      "2921\n",
      "4445\n",
      "6388\n",
      "295\n",
      "4817\n",
      "5568\n",
      "14\n",
      "3315\n",
      "5642\n",
      "3020\n",
      "5405\n",
      "6431\n",
      "4412\n",
      "513\n",
      "2931\n",
      "1141\n",
      "413\n",
      "290\n",
      "3911\n",
      "1634\n",
      "2520\n",
      "5942\n",
      "3965\n",
      "5396\n",
      "6303\n",
      "3614\n",
      "1448\n",
      "2449\n",
      "5638\n",
      "60\n",
      "1557\n",
      "4335\n",
      "570\n",
      "4393\n",
      "1610\n",
      "128\n",
      "3382\n",
      "486\n",
      "3537\n",
      "5112\n",
      "4639\n",
      "2375\n",
      "3068\n",
      "2975\n",
      "4155\n",
      "3417\n",
      "1911\n",
      "2099\n",
      "1577\n",
      "6426\n",
      "5007\n",
      "3770\n",
      "6249\n",
      "2372\n",
      "766\n",
      "970\n",
      "5309\n",
      "64\n",
      "4698\n",
      "349\n",
      "5819\n",
      "2827\n",
      "5741\n",
      "4568\n",
      "2597\n",
      "3113\n",
      "642\n",
      "5864\n",
      "6201\n",
      "1047\n",
      "5346\n",
      "1697\n",
      "2881\n",
      "3329\n",
      "4965\n",
      "4158\n",
      "2402\n",
      "3840\n",
      "5001\n",
      "1407\n",
      "89\n",
      "4265\n",
      "811\n",
      "1299\n",
      "3892\n",
      "5193\n",
      "6097\n",
      "2268\n",
      "226\n",
      "2605\n",
      "4564\n",
      "482\n",
      "6091\n",
      "3645\n",
      "4473\n",
      "2\n",
      "4942\n",
      "2077\n",
      "4818\n",
      "1057\n",
      "3333\n",
      "1401\n",
      "3666\n",
      "5366\n",
      "5526\n",
      "3470\n",
      "5679\n",
      "895\n",
      "3127\n",
      "1636\n",
      "2418\n",
      "308\n",
      "4865\n",
      "3860\n",
      "4959\n",
      "4341\n",
      "3005\n",
      "1015\n",
      "5576\n",
      "5324\n",
      "5166\n",
      "5191\n",
      "4395\n",
      "5509\n",
      "2962\n",
      "1972\n",
      "4066\n",
      "3609\n",
      "1075\n",
      "5421\n",
      "3104\n",
      "3119\n",
      "2445\n",
      "2590\n",
      "1853\n",
      "2172\n",
      "2106\n",
      "4542\n",
      "607\n",
      "865\n",
      "110\n",
      "5129\n",
      "3783\n",
      "5945\n",
      "86\n",
      "5379\n",
      "6340\n",
      "495\n",
      "1679\n",
      "752\n",
      "1961\n",
      "844\n",
      "1369\n",
      "6356\n",
      "6233\n",
      "2960\n",
      "867\n",
      "428\n",
      "5607\n",
      "2466\n",
      "5085\n",
      "5839\n",
      "2011\n",
      "1377\n",
      "2513\n",
      "3081\n",
      "3297\n",
      "2788\n",
      "5316\n",
      "2974\n",
      "1730\n",
      "5307\n",
      "2321\n",
      "5558\n",
      "5545\n",
      "4746\n",
      "1511\n",
      "4442\n",
      "3830\n",
      "5842\n",
      "3983\n",
      "3610\n",
      "1728\n",
      "4747\n",
      "2105\n",
      "3281\n",
      "6145\n",
      "1977\n",
      "1600\n",
      "4006\n",
      "3573\n",
      "3702\n",
      "3054\n",
      "5450\n",
      "3749\n",
      "2079\n",
      "1217\n",
      "1831\n",
      "5161\n",
      "2017\n",
      "6151\n",
      "4804\n",
      "1713\n",
      "6005\n",
      "5014\n",
      "6223\n",
      "4327\n",
      "1904\n",
      "4556\n",
      "4751\n",
      "651\n",
      "3253\n",
      "772\n"
     ]
    }
   ],
   "source": [
    "ground_truths = get_ground_truths(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'MLP',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'TabNet',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'KNN',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'KNN',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'MLP',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'TabNet',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'KNN',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'TabNet',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'MLP',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'MLP',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'KNN',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'KNN',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'TabNet',\n",
       " 'KNN',\n",
       " 'MLP',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'MLP',\n",
       " 'SVM',\n",
       " 'TabNet',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'TabNet',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'KNN',\n",
       " 'KNN',\n",
       " 'SVM',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'MLP',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'MLP',\n",
       " 'SVM',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'CatBoost',\n",
       " 'XGBoost',\n",
       " 'XGBoost',\n",
       " 'SVM',\n",
       " 'SVM',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, scores = get_predictions(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'CatBoost',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " 'LinearModel',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8122798589675773],\n",
       " [0.8122797114795718],\n",
       " [0.8122798641512541],\n",
       " [0.8122797164702753],\n",
       " [0.812279635330844],\n",
       " [0.812279672873802],\n",
       " [0.812279673038895],\n",
       " [0.8424165852346529],\n",
       " [0.8424164377466473],\n",
       " [0.8424165904183296],\n",
       " [0.8424164427373508],\n",
       " [0.8424163615979195],\n",
       " [0.8424163991408774],\n",
       " [0.8424163993059706],\n",
       " [1.01815636824012],\n",
       " [1.0181562207521146],\n",
       " [1.0181563734237968],\n",
       " [1.018156225742818],\n",
       " [1.0181561446033869],\n",
       " [1.0181561821463447],\n",
       " [1.0181561823114378],\n",
       " [0.8208896022493544],\n",
       " [0.8208894547613489],\n",
       " [0.8208896074330312],\n",
       " [0.8208894597520524],\n",
       " [0.8208893786126211],\n",
       " [0.820889416155579],\n",
       " [0.8208894163206721],\n",
       " [1.0142998661981826],\n",
       " [1.014299718710177],\n",
       " [1.0142998713818594],\n",
       " [1.0142997237008804],\n",
       " [1.0142996425614492],\n",
       " [1.014299680104407],\n",
       " [1.0142996802695003],\n",
       " [0.8282231666050968],\n",
       " [0.8282230191170912],\n",
       " [0.8282231717887735],\n",
       " [0.8282230241077947],\n",
       " [0.8282229429683634],\n",
       " [0.8282229805113214],\n",
       " [0.8282229806764145],\n",
       " [0.9019601573405749],\n",
       " [0.901960008328963],\n",
       " [0.9019601610658652],\n",
       " [0.9019600139168984],\n",
       " [0.9019599328240888],\n",
       " [0.90195997107606],\n",
       " [0.90195997107606],\n",
       " [0.8227679505331025],\n",
       " [0.822767803045097],\n",
       " [0.8227679557167792],\n",
       " [0.8227678080358004],\n",
       " [0.8227677268963691],\n",
       " [0.8227677644393271],\n",
       " [0.8227677646044202],\n",
       " [0.7675351021821185],\n",
       " [0.767534954694113],\n",
       " [0.7675351073657952],\n",
       " [0.7675349596848166],\n",
       " [0.7675348785453853],\n",
       " [0.7675349160883431],\n",
       " [0.7675349162534363],\n",
       " [0.612102367267205],\n",
       " [0.6121022197791957],\n",
       " [0.6121023724508416],\n",
       " [0.6121022247698773],\n",
       " [0.6121021436304561],\n",
       " [0.6121021811734193],\n",
       " [0.612102181338521],\n",
       " [0.7812666909118631],\n",
       " [0.7812665434238608],\n",
       " [0.7812666960955388],\n",
       " [0.7812665484145602],\n",
       " [0.7812664672751319],\n",
       " [0.781266504818088],\n",
       " [0.7812665049831826],\n",
       " [0.8260093716915753],\n",
       " [0.8260092242035698],\n",
       " [0.826009376875252],\n",
       " [0.8260092291942732],\n",
       " [0.8260091480548419],\n",
       " [0.8260091855977999],\n",
       " [0.8260091857628931],\n",
       " [0.8424296393776459],\n",
       " [0.8424294918896404],\n",
       " [0.8424296445613227],\n",
       " [0.842429496880344],\n",
       " [0.8424294157409127],\n",
       " [0.8424294532838705],\n",
       " [0.8424294534489637],\n",
       " [0.8213929073123223],\n",
       " [0.8213927598141095],\n",
       " [0.8213929124345964],\n",
       " [0.821392764703553],\n",
       " [0.8213926836107435],\n",
       " [0.8213927211642227],\n",
       " [0.821392721280638],\n",
       " [0.5242109879674002],\n",
       " [0.5242108404794192],\n",
       " [0.5242109931510937],\n",
       " [0.5242108454701293],\n",
       " [0.5242107643306797],\n",
       " [0.5242108018736145],\n",
       " [0.5242108020387446],\n",
       " [0.7928667517498329],\n",
       " [0.7928666042618274],\n",
       " [0.7928667569335097],\n",
       " [0.7928666092525309],\n",
       " [0.7928665281130997],\n",
       " [0.7928665656560576],\n",
       " [0.7928665658211507],\n",
       " [0.8705571493387747],\n",
       " [0.8705570018507692],\n",
       " [0.8705571545224515],\n",
       " [0.8705570068414727],\n",
       " [0.8705569257020415],\n",
       " [0.8705569632449994],\n",
       " [0.8705569634100925],\n",
       " [1.0374696474342568],\n",
       " [1.037469499936044],\n",
       " [1.0374696526147387],\n",
       " [1.037469504941903],\n",
       " [1.0374694237908857],\n",
       " [1.037469461344365],\n",
       " [1.037469461518988],\n",
       " [0.8281123583439417],\n",
       " [0.8281122108559362],\n",
       " [0.8281123635276185],\n",
       " [0.8281122158466397],\n",
       " [0.8281121347072085],\n",
       " [0.8281121722501663],\n",
       " [0.8281121724152595],\n",
       " [0.8341869802049864],\n",
       " [0.8341868327169809],\n",
       " [0.8341869853886632],\n",
       " [0.8341868377076844],\n",
       " [0.8341867565682531],\n",
       " [0.834186794111211],\n",
       " [0.8341867942763042],\n",
       " [0.8429863416519152],\n",
       " [0.8429861941609784],\n",
       " [0.842986346832397],\n",
       " [0.8429861991522853],\n",
       " [0.842986118012182],\n",
       " [0.8429861555583853],\n",
       " [0.8429861557184564],\n",
       " [0.9724465260499002],\n",
       " [0.9724463785618946],\n",
       " [0.9724465312335769],\n",
       " [0.9724463835525982],\n",
       " [0.9724463024131669],\n",
       " [0.9724463399561247],\n",
       " [0.972446340121218],\n",
       " [1.0144817941412831],\n",
       " [1.0144816466532776],\n",
       " [1.01448179932496],\n",
       " [1.014481651643981],\n",
       " [1.0144815705045498],\n",
       " [1.0144816080475076],\n",
       " [1.014481608212601],\n",
       " [0.7788504340850613],\n",
       " [0.7788502865970555],\n",
       " [0.778850439268737],\n",
       " [0.7788502915877584],\n",
       " [0.7788502104483266],\n",
       " [0.7788502479912862],\n",
       " [0.7788502481563773],\n",
       " [0.1031177236196823],\n",
       " [0.10311757613170136],\n",
       " [0.10311772880334735],\n",
       " [0.10311758112232616],\n",
       " [0.10311749998290498],\n",
       " [0.10311753752592501],\n",
       " [0.1031175376909983],\n",
       " [1.0179633646678823],\n",
       " [1.0179632171798767],\n",
       " [1.017963369851559],\n",
       " [1.01796322217058],\n",
       " [1.017963141031149],\n",
       " [1.0179631785741068],\n",
       " [1.0179631787392],\n",
       " [0.7928144951214313],\n",
       " [0.7928143476334257],\n",
       " [0.7928145003051081],\n",
       " [0.7928143526241292],\n",
       " [0.792814271484698],\n",
       " [0.7928143090276559],\n",
       " [0.7928143091927489],\n",
       " [0.7356342941682992],\n",
       " [0.7356341466802936],\n",
       " [0.735634299351976],\n",
       " [0.7356341516709972],\n",
       " [0.7356340705315659],\n",
       " [0.7356341080745238],\n",
       " [0.735634108239617],\n",
       " [0.8080840504432059],\n",
       " [0.8080839030614084],\n",
       " [0.8080840556818953],\n",
       " [0.8080839080672673],\n",
       " [0.8080838268580424],\n",
       " [0.8080838644115216],\n",
       " [0.8080838645279369],\n",
       " [0.7574328074807481],\n",
       " [0.7574326599927426],\n",
       " [0.757432812664425],\n",
       " [0.7574326649834462],\n",
       " [0.7574325838440149],\n",
       " [0.7574326213869728],\n",
       " [0.7574326215520659],\n",
       " [0.8642705661532983],\n",
       " [0.8642704186652928],\n",
       " [0.864270571336975],\n",
       " [0.8642704236559963],\n",
       " [0.864270342516565],\n",
       " [0.864270380059523],\n",
       " [0.8642703802246161],\n",
       " [0.8184785704525553],\n",
       " [0.8184784229645499],\n",
       " [0.8184785756362322],\n",
       " [0.8184784279552534],\n",
       " [0.8184783468158221],\n",
       " [0.81847838435878],\n",
       " [0.8184783845238731],\n",
       " [0.7357274291448669],\n",
       " [0.7357272816568614],\n",
       " [0.7357274343285437],\n",
       " [0.7357272866475649],\n",
       " [0.7357272055081336],\n",
       " [0.7357272430510915],\n",
       " [0.7357272432161847],\n",
       " [0.8432068530602447],\n",
       " [0.8432067055722391],\n",
       " [0.8432068582439214],\n",
       " [0.8432067105629426],\n",
       " [0.8432066294235113],\n",
       " [0.8432066669664692],\n",
       " [0.8432066671315623],\n",
       " [0.8236662373756779],\n",
       " [0.8236660898876723],\n",
       " [0.8236662425593546],\n",
       " [0.8236660948783758],\n",
       " [0.8236660137389445],\n",
       " [0.8236660512819025],\n",
       " [0.8236660514469957],\n",
       " [0.8108896626987059],\n",
       " [0.8108895152106965],\n",
       " [0.8108896678823851],\n",
       " [0.8108895202014066],\n",
       " [0.8108894390619712],\n",
       " [0.8108894766049344],\n",
       " [0.8108894767700219],\n",
       " [0.5804089914568556],\n",
       " [0.5804088439688502],\n",
       " [0.5804089966405325],\n",
       " [0.5804088489595537],\n",
       " [0.5804087678201224],\n",
       " [0.5804088053630803],\n",
       " [0.5804088055281734],\n",
       " [0.7619094808605464],\n",
       " [0.7619093333725409],\n",
       " [0.7619094860442235],\n",
       " [0.7619093383632445],\n",
       " [0.7619092572238131],\n",
       " [0.7619092947667709],\n",
       " [0.7619092949318642],\n",
       " [0.8866994599917424],\n",
       " [0.8866993125037401],\n",
       " [0.8866994651754216],\n",
       " [0.8866993174944431],\n",
       " [0.8866992363550112],\n",
       " [0.8866992738979673],\n",
       " [0.8866992740630619],\n",
       " [0.688670901558005],\n",
       " [0.6886707540699104],\n",
       " [0.6886709067416701],\n",
       " [0.6886707590606489],\n",
       " [0.6886706779212277],\n",
       " [0.6886707154642477],\n",
       " [0.688670715629321],\n",
       " [0.8177684141752926],\n",
       " [0.8177682666872871],\n",
       " [0.8177684193589694],\n",
       " [0.8177682716779906],\n",
       " [0.8177681905385593],\n",
       " [0.8177682280815172],\n",
       " [0.8177682282466103],\n",
       " [0.8471646345375416],\n",
       " [0.8471644870502428],\n",
       " [0.8471646397216614],\n",
       " [0.8471644920379118],\n",
       " [0.8471644109014465],\n",
       " [0.8471644484440117],\n",
       " [0.8471644486077208],\n",
       " [0.8087678949928961],\n",
       " [0.8087677475048907],\n",
       " [0.808767900176573],\n",
       " [0.8087677524955942],\n",
       " [0.8087676713561629],\n",
       " [0.8087677088991208],\n",
       " [0.8087677090642139],\n",
       " [0.6205560597760564],\n",
       " [0.620555912394259],\n",
       " [0.6205560650147459],\n",
       " [0.6205559174001178],\n",
       " [0.6205558361908929],\n",
       " [0.6205558737443722],\n",
       " [0.6205558738607875],\n",
       " [0.8125514020563418],\n",
       " [0.8125512545683363],\n",
       " [0.8125514072400186],\n",
       " [0.8125512595590398],\n",
       " [0.8125511784196086],\n",
       " [0.8125512159625665],\n",
       " [0.8125512161276596],\n",
       " [0.6576591370573961],\n",
       " [0.6576589895693905],\n",
       " [0.6576591422410728],\n",
       " [0.657658994560094],\n",
       " [0.6576589134206627],\n",
       " [0.6576589509636206],\n",
       " [0.6576589511287138],\n",
       " [0.7571149407169875],\n",
       " [0.757114793228982],\n",
       " [0.7571149459006643],\n",
       " [0.7571147982196855],\n",
       " [0.7571147170802542],\n",
       " [0.7571147546232122],\n",
       " [0.7571147547883053],\n",
       " [0.9005062343955001],\n",
       " [0.9005060868972874],\n",
       " [0.900506239575982],\n",
       " [0.9005060919031462],\n",
       " [0.900506010752129],\n",
       " [0.9005060483056082],\n",
       " [0.9005060484511274],\n",
       " [0.860888786477086],\n",
       " [0.8608886389890804],\n",
       " [0.8608887916607626],\n",
       " [0.8608886439797838],\n",
       " [0.8608885628403526],\n",
       " [0.8608886003833105],\n",
       " [0.8608886005484038],\n",
       " [0.797956491839116],\n",
       " [0.7979563443511105],\n",
       " [0.7979564970227928],\n",
       " [0.797956349341814],\n",
       " [0.7979562682023827],\n",
       " [0.7979563057453406],\n",
       " [0.7979563059104338],\n",
       " [0.8694809957414361],\n",
       " [0.8694808482534306],\n",
       " [0.8694810009251128],\n",
       " [0.869480853244134],\n",
       " [0.8694807721047028],\n",
       " [0.8694808096476607],\n",
       " [0.8694808098127539],\n",
       " [0.84770806053951],\n",
       " [0.8477079130995049],\n",
       " [0.8477080657781995],\n",
       " [0.8477079181053637],\n",
       " [0.8477078369543465],\n",
       " [0.847707874449618],\n",
       " [0.8477078746824487],\n",
       " [0.7707066621607682],\n",
       " [0.7707065146727626],\n",
       " [0.7707066673444449],\n",
       " [0.7707065196634661],\n",
       " [0.7707064385240349],\n",
       " [0.7707064760669928],\n",
       " [0.7707064762320859],\n",
       " [1.0495996182022578],\n",
       " [1.0495996182022578],\n",
       " [1.0495996182022578],\n",
       " [1.0495996182022578],\n",
       " [1.0495995203456419],\n",
       " [1.0495996182022578],\n",
       " [1.0495996182022578],\n",
       " [0.8711322744080758],\n",
       " [0.8711321269098631],\n",
       " [0.8711322795885577],\n",
       " [0.8711321319157219],\n",
       " [0.8711320507647047],\n",
       " [0.8711320883181839],\n",
       " [0.8711320884928069],\n",
       " [0.8230164887344459],\n",
       " [0.8230163412464403],\n",
       " [0.8230164939181226],\n",
       " [0.8230163462371438],\n",
       " [0.8230162650977125],\n",
       " [0.8230163026406705],\n",
       " [0.8230163028057637],\n",
       " [0.7623705701963741],\n",
       " [0.7623704227083932],\n",
       " [0.7623705753801528],\n",
       " [0.7623704276991317],\n",
       " [0.7623703465597105],\n",
       " [0.7623703841026168],\n",
       " [0.7623703842678038],\n",
       " [0.860368424359476],\n",
       " [0.8603682768714704],\n",
       " [0.8603684295431527],\n",
       " [0.8603682818621738],\n",
       " [0.8603682007227427],\n",
       " [0.8603682382657006],\n",
       " [0.8603682384307937],\n",
       " [0.8318188364566599],\n",
       " [0.8318186889686544],\n",
       " [0.8318188416403367],\n",
       " [0.8318186939593579],\n",
       " [0.8318186128199266],\n",
       " [0.8318186503628845],\n",
       " [0.8318186505279777],\n",
       " [0.8609507335346744],\n",
       " [0.8609505860466689],\n",
       " [0.860950738718351],\n",
       " [0.8609505910373725],\n",
       " [0.8609505098979411],\n",
       " [0.8609505474408989],\n",
       " [0.8609505476059922],\n",
       " [0.704033682020629],\n",
       " [0.7040335345333302],\n",
       " [0.7040336872047488],\n",
       " [0.7040335395246371],\n",
       " [0.7040334583845338],\n",
       " [0.7040334959270991],\n",
       " [0.7040334960926271],\n",
       " [0.7079207345474356],\n",
       " [0.7079205870592273],\n",
       " [0.707920739730646],\n",
       " [0.7079205920505343],\n",
       " [0.707920510910431],\n",
       " [0.7079205484539057],\n",
       " [0.7079205486185243],\n",
       " [0.8784058949051672],\n",
       " [0.8784057474171616],\n",
       " [0.8784059000888439],\n",
       " [0.8784057524078651],\n",
       " [0.8784056712684338],\n",
       " [0.8784057088113918],\n",
       " [0.878405708976485],\n",
       " [0.8257667551736061],\n",
       " [0.8257666076856006],\n",
       " [0.8257667603572829],\n",
       " [0.8257666126763041],\n",
       " [0.8257665315368728],\n",
       " [0.8257665690798307],\n",
       " [0.8257665692449239],\n",
       " [0.8208667376216044],\n",
       " [0.820866590133599],\n",
       " [0.8208667428052812],\n",
       " [0.8208665951243024],\n",
       " [0.8208665139848711],\n",
       " [0.8208665515278291],\n",
       " [0.8208665516929222],\n",
       " [0.8227679505331025],\n",
       " [0.822767803045097],\n",
       " [0.8227679557167792],\n",
       " [0.8227678080358004],\n",
       " [0.8227677268963691],\n",
       " [0.8227677644393271],\n",
       " [0.8227677646044202],\n",
       " [0.8192695637222369],\n",
       " [0.8192694162341991],\n",
       " [0.8192695689058451],\n",
       " [0.8192694212249376],\n",
       " [0.8192693400854596],\n",
       " [0.8192693776284228],\n",
       " [0.8192693777934961],\n",
       " [0.8984922561381905],\n",
       " [0.8984921086399777],\n",
       " [0.8984922613186723],\n",
       " [0.8984921136167328],\n",
       " [0.8984920324948193],\n",
       " [0.8984920700191947],\n",
       " [0.8984920701938177],\n",
       " [0.984468611672703],\n",
       " [0.9844684641744903],\n",
       " [0.9844686168531849],\n",
       " [0.9844684691803491],\n",
       " [0.9844683880293319],\n",
       " [0.9844684255828111],\n",
       " [0.9844684257283303],\n",
       " [0.8940376768741579],\n",
       " [0.8940375293861523],\n",
       " [0.8940376820578346],\n",
       " [0.8940375343768558],\n",
       " [0.8940374532374246],\n",
       " [0.8940374907803825],\n",
       " [0.8940374909454756],\n",
       " [0.8298039195530078],\n",
       " [0.829803772054795],\n",
       " [0.829803924675282],\n",
       " [0.8298037769442386],\n",
       " [0.829803695851429],\n",
       " [0.8298037334049082],\n",
       " [0.8298037335213235],\n",
       " [0.851735590182791],\n",
       " [0.85173544269481],\n",
       " [0.8517355953665697],\n",
       " [0.8517354476855485],\n",
       " [0.8517353665461274],\n",
       " [0.8517354040890337],\n",
       " [0.8517354042542207],\n",
       " [0.8245444790585448],\n",
       " [0.8245443315705393],\n",
       " [0.8245444842422216],\n",
       " [0.8245443365612428],\n",
       " [0.8245442554218115],\n",
       " [0.8245442929647694],\n",
       " [0.8245442931298625],\n",
       " [0.984468611672703],\n",
       " [0.9844684641744903],\n",
       " [0.9844686168531849],\n",
       " [0.9844684691803491],\n",
       " [0.9844683880293319],\n",
       " [0.9844684255828111],\n",
       " [0.9844684257283303],\n",
       " [0.8424296393776459],\n",
       " [0.8424294918896404],\n",
       " [0.8424296445613227],\n",
       " [0.842429496880344],\n",
       " [0.8424294157409127],\n",
       " [0.8424294532838705],\n",
       " [0.8424294534489637],\n",
       " [0.6099892231435786],\n",
       " [0.6099890756555977],\n",
       " [0.6099892283272437],\n",
       " [0.6099890806462793],\n",
       " [0.6099889995068581],\n",
       " [0.6099890370497929],\n",
       " [0.609989037214923],\n",
       " [0.7916204028219199],\n",
       " [0.7916202553339144],\n",
       " [0.7916204080055966],\n",
       " [0.7916202603246179],\n",
       " [0.7916201791851867],\n",
       " [0.7916202167281445],\n",
       " [0.7916202168932377],\n",
       " [0.9609786860202642],\n",
       " [0.9609785385322587],\n",
       " [0.9609786912039411],\n",
       " [0.9609785435229622],\n",
       " [0.9609784623835309],\n",
       " [0.9609784999264888],\n",
       " [0.9609785000915819],\n",
       " [0.8235339003449667],\n",
       " [0.8235337528569612],\n",
       " [0.8235339055286435],\n",
       " [0.8235337578476646],\n",
       " [0.8235336767082334],\n",
       " [0.8235337142511913],\n",
       " [0.8235337144162844],\n",
       " [0.8865130301607314],\n",
       " [0.8865128826727291],\n",
       " [0.8865130353444106],\n",
       " [0.8865128876634321],\n",
       " [0.8865128065240002],\n",
       " [0.8865128440669563],\n",
       " [0.8865128442320509],\n",
       " [0.7709247081553282],\n",
       " [0.7709245606673227],\n",
       " [0.7709247133390049],\n",
       " [0.7709245656580261],\n",
       " [0.770924484518595],\n",
       " [0.7709245220615528],\n",
       " [0.770924522226646],\n",
       " [0.831937359569717],\n",
       " [0.8319372120817115],\n",
       " [0.8319373647533937],\n",
       " [0.831937217072415],\n",
       " [0.8319371359329837],\n",
       " [0.8319371734759415],\n",
       " [0.8319371736410347],\n",
       " [0.6882056088352397],\n",
       " [0.6882054613472588],\n",
       " [0.6882056140190185],\n",
       " [0.6882054663379973],\n",
       " [0.6882053851985761],\n",
       " [0.6882054227414824],\n",
       " [0.6882054229066694],\n",
       " [0.7859648119050741],\n",
       " [0.7859646644170686],\n",
       " [0.7859648170887509],\n",
       " [0.7859646694077721],\n",
       " [0.7859645882683408],\n",
       " [0.7859646258112988],\n",
       " [0.7859646259763918],\n",
       " [0.8228363565957395],\n",
       " [0.8228362091077339],\n",
       " [0.8228363617794162],\n",
       " [0.8228362140984374],\n",
       " [0.8228361329590062],\n",
       " [0.822836170501964],\n",
       " [0.8228361706670572],\n",
       " [0.7908565279456699],\n",
       " [0.7908563804576643],\n",
       " [0.7908565331293466],\n",
       " [0.7908563854483678],\n",
       " [0.7908563043089365],\n",
       " [0.7908563418518945],\n",
       " [0.7908563420169875],\n",
       " [0.9019601573405749],\n",
       " [0.901960008328963],\n",
       " [0.9019601610658652],\n",
       " [0.9019600139168984],\n",
       " [0.9019599328240888],\n",
       " [0.90195997107606],\n",
       " [0.90195997107606],\n",
       " [0.8258961829306508],\n",
       " [0.8258960354426453],\n",
       " [0.8258961881143276],\n",
       " [0.8258960404333489],\n",
       " [0.8258959592939176],\n",
       " [0.8258959968368754],\n",
       " [0.8258959970019686],\n",
       " [0.8247186129690777],\n",
       " [0.8247184654810722],\n",
       " [0.8247186181527544],\n",
       " [0.8247184704717756],\n",
       " [0.8247183893323443],\n",
       " [0.8247184268753023],\n",
       " [0.8247184270403954],\n",
       " [0.7708544167580849],\n",
       " [0.7708542692700793],\n",
       " [0.7708544219417616],\n",
       " [0.7708542742607828],\n",
       " [0.7708541931213515],\n",
       " [0.7708542306643095],\n",
       " [0.7708542308294026],\n",
       " [0.9358738490601739],\n",
       " [0.9358737015721683],\n",
       " [0.9358738542438506],\n",
       " [0.9358737065628718],\n",
       " [0.9358736254234405],\n",
       " [0.9358736629663984],\n",
       " [0.9358736631314917],\n",
       " [0.7431375148803381],\n",
       " [0.7431373673923287],\n",
       " [0.7431375200640173],\n",
       " [0.7431373723830246],\n",
       " [0.7431372912436034],\n",
       " [0.7431373287865666],\n",
       " [0.7431373289516541],\n",
       " [0.6476208940990911],\n",
       " [0.6476207466110855],\n",
       " [0.6476208992827677],\n",
       " [0.6476207516017891],\n",
       " [0.6476206704623577],\n",
       " [0.6476207080053156],\n",
       " [0.6476207081704088],\n",
       " [0.8124359720651797],\n",
       " [0.8124358245771741],\n",
       " [0.8124359772488564],\n",
       " [0.8124358295678776],\n",
       " [0.8124357484284463],\n",
       " [0.8124357859714042],\n",
       " [0.8124357861364975],\n",
       " [0.8618148174306339],\n",
       " [0.8618146699324212],\n",
       " [0.8618148225529081],\n",
       " [0.8618146748218647],\n",
       " [0.8618145937290551],\n",
       " [0.8618146312825343],\n",
       " [0.8618146313989496],\n",
       " [0.6502682364813179],\n",
       " [0.6502680889933123],\n",
       " [0.6502682416649945],\n",
       " [0.650268093984016],\n",
       " [0.6502680128445846],\n",
       " [0.6502680503875424],\n",
       " [0.6502680505526357],\n",
       " [0.6884052443339284],\n",
       " [0.6884050968459474],\n",
       " [0.6884052495177071],\n",
       " [0.6884051018366859],\n",
       " [0.6884050206972647],\n",
       " [0.6884050582401711],\n",
       " [0.688405058405358],\n",
       " [0.8098062674303791],\n",
       " [0.8098061199423735],\n",
       " [0.8098062726140558],\n",
       " [0.809806124933077],\n",
       " [0.8098060437936457],\n",
       " [0.8098060813366036],\n",
       " [0.8098060815016968],\n",
       " [0.8615966593413333],\n",
       " [0.8615965118533278],\n",
       " [0.8615966645250099],\n",
       " [0.8615965168440314],\n",
       " [0.8615964357046],\n",
       " [0.8615964732475578],\n",
       " [0.8615964734126511],\n",
       " [0.8229923095678588],\n",
       " [0.8229921620798534],\n",
       " [0.8229923147515357],\n",
       " [0.8229921670705569],\n",
       " [0.8229920859311256],\n",
       " [0.8229921234740835],\n",
       " [0.8229921236391766],\n",
       " [0.762783182346318],\n",
       " [0.7627830348582234],\n",
       " [0.7627831875299831],\n",
       " [0.7627830398489619],\n",
       " [0.7627829587095407],\n",
       " [0.7627829962525607],\n",
       " [0.762782996417634],\n",
       " [0.7827827618792625],\n",
       " [0.7827826143912571],\n",
       " [0.7827827670629393],\n",
       " [0.7827826193819606],\n",
       " [0.7827825382425293],\n",
       " [0.7827825757854872],\n",
       " [0.7827825759505803],\n",
       " [0.8258704696660429],\n",
       " [0.8258703221780374],\n",
       " [0.8258704748497196],\n",
       " [0.8258703271687409],\n",
       " [0.8258702460293096],\n",
       " [0.8258702835722674],\n",
       " [0.8258702837373606],\n",
       " [0.8859832122367448],\n",
       " [0.8859830647486502],\n",
       " [0.8859832174204099],\n",
       " [0.8859830697393887],\n",
       " [0.8859829885999675],\n",
       " [0.8859830261428738],\n",
       " [0.8859830263080608],\n",
       " [0.8634316127737244],\n",
       " [0.8634314652857189],\n",
       " [0.8634316179574012],\n",
       " [0.8634314702764224],\n",
       " [0.8634313891369911],\n",
       " [0.863431426679949],\n",
       " [0.8634314268450421],\n",
       " [0.8632895215053156],\n",
       " [0.8632893740173101],\n",
       " [0.8632895266889924],\n",
       " [0.8632893790080136],\n",
       " [0.8632892978685823],\n",
       " [0.8632893354115402],\n",
       " [0.8632893355766333],\n",
       " [0.7053369952660729],\n",
       " [0.7053368477778645],\n",
       " [0.7053370004492832],\n",
       " [0.7053368527691715],\n",
       " [0.7053367716290682],\n",
       " [0.7053368091725429],\n",
       " [0.7053368093371615],\n",
       " [0.6205560597760564],\n",
       " [0.620555912394259],\n",
       " [0.6205560650147459],\n",
       " [0.6205559174001178],\n",
       " [0.6205558361908929],\n",
       " [0.6205558737443722],\n",
       " [0.6205558738607875],\n",
       " [0.9356034938763264],\n",
       " [0.9356033463883209],\n",
       " [0.9356034990600032],\n",
       " [0.9356033513790244],\n",
       " [0.9356032702395931],\n",
       " [0.935603307782551],\n",
       " [0.9356033079476441],\n",
       " [0.7571149407169875],\n",
       " [0.757114793228982],\n",
       " [0.7571149459006643],\n",
       " [0.7571147982196855],\n",
       " [0.7571147170802542],\n",
       " [0.7571147546232122],\n",
       " [0.7571147547883053],\n",
       " [0.5810772281680343],\n",
       " [0.5810770806800288],\n",
       " [0.5810772333517111],\n",
       " [0.5810770856707324],\n",
       " [0.5810770045313011],\n",
       " [0.581077042074259],\n",
       " [0.5810770422393521],\n",
       " [0.8525227524692985],\n",
       " [0.852522604981293],\n",
       " [0.8525227576529752],\n",
       " [0.8525226099719966],\n",
       " [0.8525225288325652],\n",
       " [0.8525225663755231],\n",
       " [0.8525225665406163],\n",
       " [0.809505787485931],\n",
       " [0.8095056399979256],\n",
       " [0.8095057926696079],\n",
       " [0.8095056449886291],\n",
       " [0.8095055638491978],\n",
       " [0.8095056013921557],\n",
       " [0.8095056015572488],\n",
       " [1.0156533348210999],\n",
       " [1.0156531873330943],\n",
       " [1.0156533400047767],\n",
       " [1.015653192323798],\n",
       " [1.0156531111843665],\n",
       " [1.0156531487273246],\n",
       " [1.0156531488924176],\n",
       " [0.8187031086693162],\n",
       " [0.8187029611813106],\n",
       " [0.8187031138529929],\n",
       " [0.8187029661720141],\n",
       " [0.8187028850325828],\n",
       " [0.8187029225755407],\n",
       " [0.8187029227406338],\n",
       " [0.8178523299496393],\n",
       " [0.8178521824616337],\n",
       " [0.817852335133316],\n",
       " [0.8178521874523372],\n",
       " [0.817852106312906],\n",
       " [0.8178521438558639],\n",
       " [0.8178521440209571],\n",
       " [1.0417871182022578],\n",
       " [1.0417871182022578],\n",
       " [1.0417871182022578],\n",
       " [1.0417871182022578],\n",
       " [1.0417870203456419],\n",
       " [1.0417871182022578],\n",
       " [1.0417871182022578],\n",
       " [0.7431375148803381],\n",
       " [0.7431373673923287],\n",
       " [0.7431375200640173],\n",
       " [0.7431373723830246],\n",
       " [0.7431372912436034],\n",
       " [0.7431373287865666],\n",
       " [0.7431373289516541],\n",
       " [0.8694855973649875],\n",
       " [0.869485449876982],\n",
       " [0.8694856025486642],\n",
       " [0.8694854548676855],\n",
       " [0.8694853737282542],\n",
       " [0.869485411271212],\n",
       " [0.8694854114363053],\n",
       " [0.8185670108217165],\n",
       " [0.8185668633336787],\n",
       " [0.8185670160053247],\n",
       " [0.8185668683243603],\n",
       " [0.8185667871849391],\n",
       " [0.8185668247279023],\n",
       " [0.8185668248929756],\n",
       " [0.7635994582751733],\n",
       " [0.7635993107871923],\n",
       " [0.763599463458952],\n",
       " [0.7635993157779308],\n",
       " [0.7635992346385096],\n",
       " [0.763599272181416],\n",
       " [0.763599272346603],\n",
       " [1.0144120110651704],\n",
       " [1.0144118635771648],\n",
       " [1.0144120162488472],\n",
       " [1.0144118685678685],\n",
       " [1.014411787428437],\n",
       " [1.0144118249713951],\n",
       " [1.0144118251364882],\n",
       " [0.8284250657722931],\n",
       " [0.8284249182842875],\n",
       " [0.8284250709559698],\n",
       " [0.8284249232749911],\n",
       " [0.8284248421355598],\n",
       " [0.8284248796785176],\n",
       " [0.8284248798436109],\n",
       " [0.8346147666167965],\n",
       " [0.8346146191287909],\n",
       " [0.8346147718004732],\n",
       " [0.8346146241194944],\n",
       " [0.8346145429800631],\n",
       " [0.834614580523021],\n",
       " [0.8346145806881142],\n",
       " [0.7827072948319651],\n",
       " [0.7827071473439596],\n",
       " [0.7827073000156418],\n",
       " [0.7827071523346631],\n",
       " [0.7827070711952319],\n",
       " [0.7827071087381897],\n",
       " [0.7827071089032829],\n",
       " [0.9724465260499002],\n",
       " [0.9724463785618946],\n",
       " [0.9724465312335769],\n",
       " [0.9724463835525982],\n",
       " [0.9724463024131669],\n",
       " [0.9724463399561247],\n",
       " [0.972446340121218],\n",
       " [0.8113658441747025],\n",
       " [0.8113656966866969],\n",
       " [0.8113658493583792],\n",
       " [0.8113657016774004],\n",
       " [0.8113656205379691],\n",
       " [0.8113656580809271],\n",
       " [0.8113656582460202],\n",
       " [0.8049924966048123],\n",
       " [0.8049923491168068],\n",
       " [0.8049925017884891],\n",
       " [0.8049923541075104],\n",
       " [0.8049922729680791],\n",
       " [0.8049923105110369],\n",
       " [0.8049923106761301],\n",
       " [0.9356034938763264],\n",
       " [0.9356033463883209],\n",
       " [0.9356034990600032],\n",
       " [0.9356033513790244],\n",
       " [0.9356032702395931],\n",
       " [0.935603307782551],\n",
       " [0.9356033079476441],\n",
       " [0.7709174243442907],\n",
       " [0.7709172768562852],\n",
       " [0.7709174295279675],\n",
       " [0.7709172818469887],\n",
       " [0.7709172007075574],\n",
       " [0.7709172382505153],\n",
       " [0.7709172384156084],\n",
       " [0.860888786477086],\n",
       " [0.8608886389890804],\n",
       " [0.8608887916607626],\n",
       " [0.8608886439797838],\n",
       " [0.8608885628403526],\n",
       " [0.8608886003833105],\n",
       " [0.8608886005484038],\n",
       " [0.8464910079225161],\n",
       " [0.8464908604352173],\n",
       " [0.8464910131066359],\n",
       " [0.8464908654265242],\n",
       " [0.8464907842864209],\n",
       " [0.8464908218289862],\n",
       " [0.8464908219926952],\n",
       " [0.9003619527380875],\n",
       " [0.9003618053562901],\n",
       " [0.900361957976777],\n",
       " [0.9003618103621489],\n",
       " [0.900361729152924],\n",
       " [0.9003617667064032],\n",
       " [0.9003617668228185],\n",
       " [0.7827072948319651],\n",
       " [0.7827071473439596],\n",
       " [0.7827073000156418],\n",
       " [0.7827071523346631],\n",
       " [0.7827070711952319],\n",
       " [0.7827071087381897],\n",
       " [0.7827071089032829],\n",
       " [0.8847790151072628],\n",
       " [0.88477886760905],\n",
       " [0.8847790202295369],\n",
       " [0.8847788726149088],\n",
       " [0.8847787914056839],\n",
       " [0.8847788289591632],\n",
       " [0.8847788290755785],\n",
       " [0.9295718741322667],\n",
       " [0.9295717266442611],\n",
       " [0.9295718793159435],\n",
       " [0.9295717316349648],\n",
       " [0.9295716504955334],\n",
       " [0.9295716880384912],\n",
       " [0.9295716882035845],\n",
       " [0.8331858026107932],\n",
       " [0.8331856551227876],\n",
       " [0.8331858077944699],\n",
       " [0.8331856601134912],\n",
       " [0.8331855789740599],\n",
       " [0.8331856165170177],\n",
       " [0.833185616682111],\n",
       " [0.8110386385609908],\n",
       " [0.8110384910729853],\n",
       " [0.8110386437446676],\n",
       " [0.8110384960636888],\n",
       " [0.8110384149242575],\n",
       " [0.8110384524672154],\n",
       " [0.8110384526323086],\n",
       " [0.8395424267719773],\n",
       " [0.839542279283968],\n",
       " [0.8395424319556566],\n",
       " [0.839542284274678],\n",
       " [0.8395422031352426],\n",
       " [0.8395422406782058],\n",
       " [0.8395422408432933],\n",
       " [0.8097666324971058],\n",
       " [0.8097664850091003],\n",
       " [0.8097666376807826],\n",
       " [0.8097664899998038],\n",
       " [0.8097664088603725],\n",
       " [0.8097664464033304],\n",
       " [0.8097664465684236],\n",
       " [0.7629659692891051],\n",
       " [0.7629658218010105],\n",
       " [0.7629659744727701],\n",
       " [0.762965826791749],\n",
       " [0.7629657456523278],\n",
       " [0.7629657831953478],\n",
       " [0.7629657833604211],\n",
       " [0.809690263965034],\n",
       " [0.8096901164770285],\n",
       " [0.8096902691487108],\n",
       " [0.809690121467732],\n",
       " [0.8096900403283007],\n",
       " [0.8096900778712586],\n",
       " [0.8096900780363517],\n",
       " [0.9735412368934125],\n",
       " [0.973541089405407],\n",
       " [0.9735412420770893],\n",
       " [0.9735410943961105],\n",
       " [0.9735410132566792],\n",
       " [0.973541050799637],\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010061919504643963\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = 0\n",
    "for i in range(len(ground_truths)):\n",
    "    if (ground_truths[i] == preds[i]):\n",
    "        correct_prediction = correct_prediction + 1\n",
    "print(correct_prediction/len(ground_truths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
